{"cells":[{"cell_type":"markdown","metadata":{"id":"gjbJH5dezcyw"},"source":["##### This script essentially uses the pre-trained SVM model to perform face detection on a test image using a sliding window approach at various scales. Detected bounding box coordinates are shown on the test image, providing visual representation of detected faces."]},{"cell_type":"code","source":["!git clone https://github.com/aspagnuolo/Face_detection.git"],"metadata":{"id":"8CizENOm1Bm-","executionInfo":{"status":"ok","timestamp":1691654425487,"user_tz":-120,"elapsed":14625,"user":{"displayName":"Antonio Spagnuolo","userId":"05121116044769154137"}},"outputId":"6ec94286-4fa7-4886-baa1-d9ce01ec540a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Face_detection'...\n","remote: Enumerating objects: 7451, done.\u001b[K\n","remote: Total 7451 (delta 0), reused 0 (delta 0), pack-reused 7451\u001b[K\n","Receiving objects: 100% (7451/7451), 197.23 MiB | 18.86 MiB/s, done.\n","Updating files: 100% (7449/7449), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"5jegzs-8zcy0"},"source":["**1. Importing Required Modules and Libraries:**\n","\n","* Import functions from a custom utility module.\n","* Import the joblib library for loading the pre-trained SVM model.\n","* Import necessary classes from scikit-learn for creating custom transformers.\n","* Import the Pipeline class for creating a processing pipeline."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tpynA-Ttzcy1","executionInfo":{"status":"ok","timestamp":1691654427747,"user_tz":-120,"elapsed":2265,"user":{"displayName":"Antonio Spagnuolo","userId":"05121116044769154137"}}},"outputs":[],"source":["from Face_detection.utils import *\n","import joblib\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"markdown","metadata":{"id":"Oj6g4MuLzcy2"},"source":["**2. Loading Pre-trained SVM Model:**\n","\n","* Load a pre-trained SVM model that includes hard negatives. This model was trained using the script in _train_model.ipynb_."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ovalR2c4zcy2","executionInfo":{"status":"ok","timestamp":1691654428177,"user_tz":-120,"elapsed":435,"user":{"displayName":"Antonio Spagnuolo","userId":"05121116044769154137"}}},"outputs":[],"source":["svm_with_hard_negatives=joblib.load('/content/Face_detection/svm_with_hard_negatives')"]},{"cell_type":"markdown","metadata":{"id":"PhBlIJoEzcy3"},"source":["**3. Creating a Custom Transformer for Object Detection:**\n","\n","* ObjectDetectionTransformer class is defined, inheriting from BaseEstimator and TransformerMixin.\n","* The constructor (__init__) initializes the transformer with attributes including the pre-trained SVM model, window sizes, step size, downscale factor, and confidence threshold.\n","* detect_objects method takes an image and a window size, and performs object detection using a sliding window approach at different scales. It calculates HOG features for each window, predicts using the SVM model, and accumulates detections based on confidence scores.\n","* transform method takes input data (images) and returns detected bounding box coordinates after non-maximum suppression (see utils.py)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"H-t6z-uazcy3","executionInfo":{"status":"ok","timestamp":1691654428179,"user_tz":-120,"elapsed":10,"user":{"displayName":"Antonio Spagnuolo","userId":"05121116044769154137"}}},"outputs":[],"source":["class ObjectDetectionTransformer(BaseEstimator, TransformerMixin):\n","    def __init__(self, svm_with_hard_negatives, winSizes, stepSize, downscale, threshold):\n","        self.svm_with_hard_negatives = svm_with_hard_negatives\n","        self.winSizes = winSizes\n","        self.stepSize = stepSize\n","        self.downscale = downscale\n","        self.threshold = threshold\n","\n","    def detect_objects(self, image, winSize):\n","        detections = []\n","        for scale in np.linspace(1.0, self.downscale, 5)[::-1]:\n","            resized_image = cv2.resize(image, (int(image.shape[1] / scale), int(image.shape[0] / scale)))\n","            for (x, y, window) in sliding_window(resized_image, self.stepSize, winSize):\n","                if window.shape[0] != winSize[1] or window.shape[1] != winSize[0]:\n","                    continue\n","                features = get_hog_features(window)\n","                confidence = self.svm_with_hard_negatives.decision_function([features])[0]\n","                if confidence >= self.threshold:\n","                    x = int(x * scale)\n","                    y = int(y * scale)\n","                    w = int(winSize[0] * scale)\n","                    h = int(winSize[1] * scale)\n","                    detections.append((x, y, x + w, y + h))\n","        return detections\n","\n","    def transform(self, X, y=None):\n","        all_detections = []\n","        for winSize in self.winSizes:\n","            detections = self.detect_objects(X, winSize)\n","            all_detections.extend(detections)\n","        nms_detections = non_max_suppression(np.array(all_detections), overlap_threshold=0.2)\n","        return nms_detections"]},{"cell_type":"markdown","metadata":{"id":"uvZLMM2Uzcy4"},"source":["**4. Defining Parameters for Object Detection:**\n","\n","* winSizes: A list of window sizes (bounding box dimensions) for object detection.\n","* stepSize: Step size for sliding window approach.\n","* downscale: A factor for resizing the image to detect objects at different scales.\n","* threshold: Confidence threshold for deciding if an object is detected.\n","\n","**5. Creating an Object Detection Pipeline:**\n","\n","object_detection_pipeline is defined as a scikit-learn Pipeline with a single step using the ObjectDetectionTransformer. This pipeline encapsulates the object detection process."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"71nptbTtzcy4","executionInfo":{"status":"ok","timestamp":1691654428180,"user_tz":-120,"elapsed":10,"user":{"displayName":"Antonio Spagnuolo","userId":"05121116044769154137"}}},"outputs":[],"source":["winSizes = [(128, 128)]\n","stepSize = 10\n","downscale = 1.5\n","threshold = 0.7\n","\n","object_detection_pipeline = Pipeline([\n","    ('object_detection', ObjectDetectionTransformer(svm_with_hard_negatives, winSizes, stepSize, downscale, threshold))\n","])"]},{"cell_type":"markdown","metadata":{"id":"ye5v76n_zcy5"},"source":["**6. Loading and Preparing a Test Image:**\n","\n","* test_image_path: Path to the test image file.\n","* test_image: Load the test image using OpenCV.\n","\n","**7. Performing Object Detection:**\n","\n","nms_detections: Perform object detection using the defined pipeline on the test image.\n","If objects are detected, the bounding box coordinates are stored in the nms_detections array."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtixVftHzcy5"},"outputs":[],"source":["test_image_path = \"/content/Face_detection/test/thelastofus.jpg\"\n","test_image = cv2.imread(test_image_path)\n","\n","nms_detections = object_detection_pipeline.transform(test_image)\n","\n","if len(nms_detections) > 0:\n","    bounding_box_list = nms_detections.tolist()\n","    print(bounding_box_list)\n","else:\n","    print(\"NO FACES DETECTED IN THE IMAGE\")"]},{"cell_type":"markdown","metadata":{"id":"0de76zuVzcy5"},"source":["**8. Displaying Results:**\n","\n","* If no faces are detected, the script prints \"NO FACES DETECTED IN THE IMAGE\".\n","* If faces are detected:\n","  * The script creates a copy of the test image (result_image).\n","  * It draws green rectangles around the detected bounding boxes on result_image.\n","  * The modified image is displayed using OpenCV, showing the detected objects."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IoC3Y-w_zcy5"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","if len(nms_detections) == 0:\n","    print(\"NO FACES DETECTED IN THE IMAGE\")\n","else:\n","    result_image = test_image.copy()\n","    for (x1, y1, x2, y2) in nms_detections:\n","        cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","    cv2_imshow(result_image)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[{"file_id":"https://github.com/aspagnuolo/Face_detection/blob/main/Face_Detection.ipynb","timestamp":1691594326189}]}},"nbformat":4,"nbformat_minor":0}