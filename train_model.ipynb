{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This script is a machine learning application for training a Support Vector Machine (SVM) classifier to distinguish between positive and negative image samples. It performs data preprocessing, feature extraction, hyperparameter tuning, classifier training, evaluation, and model saving. The goal is to create a more robust classifier by augmenting the dataset, using HOG features, and incorporating hard negative mining. The script consists of several steps and components, which I'll explain in detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import Libraries:** \n",
    "\n",
    "The script starts with importing the necessary libraries, such as functions from libraries like OpenCV for image processing, scikit-learn for machine learning, and  functions from a custom utility module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define Image Directories:**\n",
    "\n",
    "* positive_images_folder: Path to the directory containing positive image samples.\n",
    "* negative_images_folder: Path to the directory containing negative image samples.\n",
    "\n",
    "**3. Load Images:**\n",
    "\n",
    "* load_positive_images() and load_negative_images(): Functions that load the positive and negative image samples from the specified folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images_folder = \"pos_dataset\"\n",
    "negative_images_folder = \"neg_dataset\"\n",
    "\n",
    "positive_images=load_positive_images(positive_images_folder)\n",
    "negative_images=load_negative_images(negative_images_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Patch Extraction and Augmentation:**\n",
    "\n",
    "* num_patches_per_image: Number of patches to extract from each negative image.\n",
    "* patch_size: Size of the patches to extract.\n",
    "* augmented_negative_images: A list to hold augmented negative image patches.\n",
    "* Loop through each negative image:\n",
    "  * Extract random patches from the image using the extract_random_patches() function.\n",
    "  * Extend the augmented_negative_images list with the extracted patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches_per_image = 3\n",
    "patch_size = (64, 64)\n",
    "augmented_negative_images=[]\n",
    "for image in negative_images:\n",
    "    patches = extract_random_patches(image, num_patches_per_image, patch_size)\n",
    "    augmented_negative_images.extend(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Simulated Distance Variation (Augmentation):**\n",
    "* scale_factors: List of scaling factors for simulating distance variation.\n",
    "* augmented_positive_images: A list to hold augmented positive images.\n",
    "* Loop through each positive image:\n",
    "  * Simulate distance variations by applying scaling to the image using the simulate_distance_variation() function.\n",
    "  * Extend the augmented_positive_images list with the simulated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factors = [1.0]\n",
    "augmented_positive_images = []\n",
    "for image in positive_images:\n",
    "    simulated_images = simulate_distance_variation(image, scale_factors)\n",
    "    augmented_positive_images.extend(simulated_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Mirror Augmentation:**\n",
    "\n",
    "* mirror_augmented_positive_images: Create mirror images of the augmented positive images.\n",
    "* Extend the mirror_augmented_positive_images list with the mirror images and the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_augmented_positive_images = add_mirror_images(augmented_positive_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Creating the Dataset and Labels:**\n",
    "\n",
    "* dataset: Combined list of augmented positive images and augmented negative image patches.\n",
    "* labels: List of labels corresponding to the dataset, where 1 represents positive samples and 0 represents negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mirror_augmented_positive_images + augmented_negative_images\n",
    "labels = [1] * len(mirror_augmented_positive_images) + [0] * len(augmented_negative_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Feature Extraction (HOG):**\n",
    "\n",
    "HOG (Histogram of Oriented Gradients) feature extraction is a technique used in computer vision and image processing. It involves analyzing the distribution of gradient orientations in an image to capture its local texture and shape information.\n",
    "* features_list: A list to store the HOG feature vectors for each image in the dataset.\n",
    "* Loop through each image in the dataset:\n",
    "  * Extract HOG features using the get_hog_features() function. This function also implements within it a second function for image resizing (see utils.py). Its deafult arguments are: \n",
    "    * _resize_width=64_\n",
    "    * _resize_height=64_ \n",
    "    * _orient = 9_ \n",
    "    * _pix_per_cell = 8_\n",
    "    * _cell_per_block = 2_\n",
    "  * Append the features to the features_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for image in dataset:\n",
    "    features = get_hog_features(image)\n",
    "    features_list.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Train-Test Split:**\n",
    "\n",
    "* Split the dataset and labels into training and testing sets using train_test_split().\n",
    "\n",
    "**10. Hyperparameter Tuning:**\n",
    "\n",
    "* param_grid: A dictionary containing the hyperparameters to be tuned (C and loss) for the SVM classifier.\n",
    "* Create an instance of LinearSVC and perform hyperparameter tuning using GridSearchCV.\n",
    "\n",
    "**11. Training the SVM Classifier:**\n",
    "\n",
    "* Train a new LinearSVC classifier with the best hyperparameters obtained from the grid search.\n",
    "* Fit the classifier using the training data.\n",
    "\n",
    "**12. Evaluation and Printing Results:**\n",
    "\n",
    "* Make predictions on the test data using the trained classifier.\n",
    "* Print a classification report that includes precision, recall, F1-score, and support for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1428\n",
      "           1       1.00      0.99      1.00      2022\n",
      "\n",
      "    accuracy                           0.99      3450\n",
      "   macro avg       0.99      0.99      0.99      3450\n",
      "weighted avg       0.99      0.99      0.99      3450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_list, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0],           \n",
    "    'loss': ['squared_hinge'],  \n",
    "}\n",
    "\n",
    "svm = LinearSVC(dual=False, random_state=42)  \n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "svm = LinearSVC(dual=False, random_state=42, C=best_params['C'], loss=best_params['loss'])\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Hard Negative Mining:** \n",
    "\n",
    "* negative_images_augmented: Take a subset of the original negative images for hard negative mining.\n",
    "* stepSize: The step size for sliding a window over the images for hard negative mining.\n",
    "* Perform hard negative mining using the hard_negative_mining() function to identify challenging negative samples. This function also implements within it a sliding window function, the portions are then submitted to the get_hog_features function and made a prediction with the trained classifier; in case the prediction == 1 (false positives), appended to an empty list (see utils.py). its deafult arguments are: windowSize = (64, 64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images_augmented = negative_images[:500] \n",
    "stepSize = 20\n",
    "\n",
    "hard_negatives = hard_negative_mining(svm, negative_images_augmented, stepSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. Updating Training Data with Hard Negatives:**\n",
    "\n",
    "* Append the HOG features of the hard negative samples to the training features.\n",
    "* Update the labels accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hard_negatives = np.vstack([X_train, [get_hog_features(img) for img in hard_negatives]])\n",
    "y_train_hard_negatives = np.concatenate([y_train, np.zeros(len(hard_negatives))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. Retraining SVM with Hard Negatives:**\n",
    "\n",
    "* Create a new LinearSVC classifier instance and train it using the updated training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=0.01, dual=False, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.01, dual=False, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=0.01, dual=False, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_with_hard_negatives = LinearSVC(dual=False, random_state=42, C=best_params['C'], loss=best_params['loss'])\n",
    "svm_with_hard_negatives.fit(X_train_hard_negatives, y_train_hard_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. Saving the Trained Model:**\n",
    "\n",
    "* Save the final trained SVM classifier (with hard negatives) using the joblib.dump() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_with_hard_negatives']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_with_hard_negatives, 'svm_with_hard_negatives')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
